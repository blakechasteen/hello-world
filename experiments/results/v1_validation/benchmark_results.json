{
  "version": "1.0.0",
  "timestamp": "2025-10-30T02:37:52.089395",
  "total_benchmarks": 26,
  "test_queries": [
    "What is Thompson Sampling?",
    "How does reinforcement learning work?",
    "Explain the difference between supervised and unsupervised learning",
    "What are the benefits of multi-scale embeddings?",
    "How do knowledge graphs improve retrieval?",
    "What is the role of attention in transformers?",
    "Explain Bayesian exploration vs exploitation",
    "What is semantic similarity?",
    "How does recursive learning improve AI systems?",
    "What are the key components of a neural network?"
  ],
  "results": [
    {
      "experiment_name": "Old Model (384d)",
      "query": "What is Thompson Sampling?",
      "model": "sentence-transformers/all-MiniLM-L12-v2",
      "scales": [
        384
      ],
      "confidence": 0.29962820858605815,
      "relevance_score": 0.85,
      "response_length": 1915,
      "latency_ms": 4577.623500023037,
      "embedding_time_ms": 2543.683800031431,
      "retrieval_time_ms": 1373.2870500069112,
      "decision_time_ms": 915.5247000046074,
      "memory_mb": 128.04296875,
      "token_count": 482,
      "timestamp": "2025-10-30T02:36:08.947074"
    },
    {
      "experiment_name": "Nomic v1.5 (768d)",
      "query": "What is Thompson Sampling?",
      "model": "nomic-ai/nomic-embed-text-v1.5",
      "scales": [
        768
      ],
      "confidence": 0.3199500942260629,
      "relevance_score": 0.85,
      "response_length": 1927,
      "latency_ms": 4491.565299918875,
      "embedding_time_ms": 2374.0750999422744,
      "retrieval_time_ms": 1347.4695899756625,
      "decision_time_ms": 898.313059983775,
      "memory_mb": 43.08203125,
      "token_count": 485,
      "timestamp": "2025-10-30T02:36:13.557783"
    },
    {
      "experiment_name": "Old Model (384d)",
      "query": "How does reinforcement learning work?",
      "model": "sentence-transformers/all-MiniLM-L12-v2",
      "scales": [
        384
      ],
      "confidence": 0.29427669225404796,
      "relevance_score": 0.85,
      "response_length": 1917,
      "latency_ms": 3893.2377999881282,
      "embedding_time_ms": 2563.579799956642,
      "retrieval_time_ms": 1167.9713399964385,
      "decision_time_ms": 778.6475599976256,
      "memory_mb": 87.69921875,
      "token_count": 484,
      "timestamp": "2025-10-30T02:36:17.491423"
    },
    {
      "experiment_name": "Nomic v1.5 (768d)",
      "query": "How does reinforcement learning work?",
      "model": "nomic-ai/nomic-embed-text-v1.5",
      "scales": [
        768
      ],
      "confidence": 0.29241612247072296,
      "relevance_score": 0.85,
      "response_length": 1892,
      "latency_ms": 4414.122799993493,
      "embedding_time_ms": 2519.33519996237,
      "retrieval_time_ms": 1324.2368399980478,
      "decision_time_ms": 882.8245599986985,
      "memory_mb": 5.24609375,
      "token_count": 478,
      "timestamp": "2025-10-30T02:36:22.029503"
    },
    {
      "experiment_name": "Old Model (384d)",
      "query": "Explain the difference between supervised and unsupervised learning",
      "model": "sentence-transformers/all-MiniLM-L12-v2",
      "scales": [
        384
      ],
      "confidence": 0.26775771192870107,
      "relevance_score": 0.85,
      "response_length": 1914,
      "latency_ms": 3769.2773999879137,
      "embedding_time_ms": 2388.898400007747,
      "retrieval_time_ms": 1130.783219996374,
      "decision_time_ms": 753.8554799975827,
      "memory_mb": 86.94140625,
      "token_count": 486,
      "timestamp": "2025-10-30T02:36:25.848007"
    },
    {
      "experiment_name": "Nomic v1.5 (768d)",
      "query": "Explain the difference between supervised and unsupervised learning",
      "model": "nomic-ai/nomic-embed-text-v1.5",
      "scales": [
        768
      ],
      "confidence": 0.30373092818128883,
      "relevance_score": 0.85,
      "response_length": 1950,
      "latency_ms": 4360.399099998176,
      "embedding_time_ms": 2411.620300030336,
      "retrieval_time_ms": 1308.1197299994528,
      "decision_time_ms": 872.0798199996352,
      "memory_mb": -41.7265625,
      "token_count": 495,
      "timestamp": "2025-10-30T02:36:30.325838"
    },
    {
      "experiment_name": "Old Model (384d)",
      "query": "What are the benefits of multi-scale embeddings?",
      "model": "sentence-transformers/all-MiniLM-L12-v2",
      "scales": [
        384
      ],
      "confidence": 0.25813760640641914,
      "relevance_score": 0.85,
      "response_length": 1900,
      "latency_ms": 3744.756400003098,
      "embedding_time_ms": 2372.357700020075,
      "retrieval_time_ms": 1123.4269200009294,
      "decision_time_ms": 748.9512800006196,
      "memory_mb": 88.15625,
      "token_count": 482,
      "timestamp": "2025-10-30T02:36:34.108756"
    },
    {
      "experiment_name": "Nomic v1.5 (768d)",
      "query": "What are the benefits of multi-scale embeddings?",
      "model": "nomic-ai/nomic-embed-text-v1.5",
      "scales": [
        768
      ],
      "confidence": 0.324738824574335,
      "relevance_score": 0.85,
      "response_length": 1917,
      "latency_ms": 3891.80830004625,
      "embedding_time_ms": 2096.698399982415,
      "retrieval_time_ms": 1167.542490013875,
      "decision_time_ms": 778.36166000925,
      "memory_mb": 5.46875,
      "token_count": 486,
      "timestamp": "2025-10-30T02:36:38.118764"
    },
    {
      "experiment_name": "Old Model (384d)",
      "query": "How do knowledge graphs improve retrieval?",
      "model": "sentence-transformers/all-MiniLM-L12-v2",
      "scales": [
        384
      ],
      "confidence": 0.3396220540764123,
      "relevance_score": 0.85,
      "response_length": 1876,
      "latency_ms": 3570.0608999468386,
      "embedding_time_ms": 2228.2194999279454,
      "retrieval_time_ms": 1071.0182699840516,
      "decision_time_ms": 714.0121799893677,
      "memory_mb": 87.58984375,
      "token_count": 475,
      "timestamp": "2025-10-30T02:36:41.729760"
    },
    {
      "experiment_name": "Nomic v1.5 (768d)",
      "query": "How do knowledge graphs improve retrieval?",
      "model": "nomic-ai/nomic-embed-text-v1.5",
      "scales": [
        768
      ],
      "confidence": 0.30244307245269175,
      "relevance_score": 0.85,
      "response_length": 1890,
      "latency_ms": 4519.14239989128,
      "embedding_time_ms": 2234.9239999894053,
      "retrieval_time_ms": 1355.742719967384,
      "decision_time_ms": 903.8284799782559,
      "memory_mb": 2.3671875,
      "token_count": 478,
      "timestamp": "2025-10-30T02:36:46.367987"
    },
    {
      "experiment_name": "Multi-scale [96,192,384]",
      "query": "What is the role of attention in transformers?",
      "model": "sentence-transformers/all-MiniLM-L12-v2",
      "scales": [
        96,
        192,
        384
      ],
      "confidence": 0.30988264707385765,
      "relevance_score": 0.85,
      "response_length": 1892,
      "latency_ms": 3998.3387000393122,
      "embedding_time_ms": 2592.0002000639215,
      "retrieval_time_ms": 1199.5016100117937,
      "decision_time_ms": 799.6677400078624,
      "memory_mb": 87.96484375,
      "token_count": 481,
      "timestamp": "2025-10-30T02:36:50.403755"
    },
    {
      "experiment_name": "Single-scale [768]",
      "query": "What is the role of attention in transformers?",
      "model": "nomic-ai/nomic-embed-text-v1.5",
      "scales": [
        768
      ],
      "confidence": 0.3400284765915091,
      "relevance_score": 0.85,
      "response_length": 1964,
      "latency_ms": 4049.4869999820367,
      "embedding_time_ms": 2254.863299895078,
      "retrieval_time_ms": 1214.846099994611,
      "decision_time_ms": 809.8973999964073,
      "memory_mb": -78.2421875,
      "token_count": 499,
      "timestamp": "2025-10-30T02:36:54.576279"
    },
    {
      "experiment_name": "Multi-scale [96,192,384]",
      "query": "Explain Bayesian exploration vs exploitation",
      "model": "sentence-transformers/all-MiniLM-L12-v2",
      "scales": [
        96,
        192,
        384
      ],
      "confidence": 0.271286107923936,
      "relevance_score": 0.85,
      "response_length": 1951,
      "latency_ms": 3712.895800010301,
      "embedding_time_ms": 2306.980299996212,
      "retrieval_time_ms": 1113.8687400030904,
      "decision_time_ms": 742.5791600020602,
      "memory_mb": 73.796875,
      "token_count": 492,
      "timestamp": "2025-10-30T02:36:58.324285"
    },
    {
      "experiment_name": "Single-scale [768]",
      "query": "Explain Bayesian exploration vs exploitation",
      "model": "nomic-ai/nomic-embed-text-v1.5",
      "scales": [
        768
      ],
      "confidence": 0.3185907256781042,
      "relevance_score": 0.85,
      "response_length": 1857,
      "latency_ms": 4220.280099892989,
      "embedding_time_ms": 2222.586899995804,
      "retrieval_time_ms": 1266.0840299678966,
      "decision_time_ms": 844.0560199785978,
      "memory_mb": 20.84375,
      "token_count": 469,
      "timestamp": "2025-10-30T02:37:02.663579"
    },
    {
      "experiment_name": "Multi-scale [96,192,384]",
      "query": "What is semantic similarity?",
      "model": "sentence-transformers/all-MiniLM-L12-v2",
      "scales": [
        96,
        192,
        384
      ],
      "confidence": 0.3026237415620576,
      "relevance_score": 0.85,
      "response_length": 1829,
      "latency_ms": 3539.3275999231264,
      "embedding_time_ms": 2218.9086999278516,
      "retrieval_time_ms": 1061.798279976938,
      "decision_time_ms": 707.8655199846253,
      "memory_mb": 76.05859375,
      "token_count": 461,
      "timestamp": "2025-10-30T02:37:06.243244"
    },
    {
      "experiment_name": "Single-scale [768]",
      "query": "What is semantic similarity?",
      "model": "nomic-ai/nomic-embed-text-v1.5",
      "scales": [
        768
      ],
      "confidence": 0.3179099205848514,
      "relevance_score": 0.85,
      "response_length": 1874,
      "latency_ms": 4024.240200058557,
      "embedding_time_ms": 2198.8492000382394,
      "retrieval_time_ms": 1207.2720600175671,
      "decision_time_ms": 804.8480400117114,
      "memory_mb": 16.8984375,
      "token_count": 472,
      "timestamp": "2025-10-30T02:37:10.372464"
    },
    {
      "experiment_name": "v1.0 (Nomic, 768d)",
      "query": "What is Thompson Sampling?",
      "model": "nomic-ai/nomic-embed-text-v1.5",
      "scales": [
        768
      ],
      "confidence": 0.28046581113156255,
      "relevance_score": 0.85,
      "response_length": 1894,
      "latency_ms": 4077.190399984829,
      "embedding_time_ms": 2141.2587999366224,
      "retrieval_time_ms": 1223.1571199954487,
      "decision_time_ms": 815.4380799969658,
      "memory_mb": 4.78125,
      "token_count": 477,
      "timestamp": "2025-10-30T02:37:14.555395"
    },
    {
      "experiment_name": "v1.0 (Nomic, 768d)",
      "query": "How does reinforcement learning work?",
      "model": "nomic-ai/nomic-embed-text-v1.5",
      "scales": [
        768
      ],
      "confidence": 0.3170939082681705,
      "relevance_score": 0.85,
      "response_length": 1880,
      "latency_ms": 4072.8287999518216,
      "embedding_time_ms": 2155.6459999410436,
      "retrieval_time_ms": 1221.8486399855465,
      "decision_time_ms": 814.5657599903643,
      "memory_mb": 6.0625,
      "token_count": 475,
      "timestamp": "2025-10-30T02:37:18.754564"
    },
    {
      "experiment_name": "v1.0 (Nomic, 768d)",
      "query": "Explain the difference between supervised and unsupervised learning",
      "model": "nomic-ai/nomic-embed-text-v1.5",
      "scales": [
        768
      ],
      "confidence": 0.29703849515406133,
      "relevance_score": 0.85,
      "response_length": 1900,
      "latency_ms": 4081.001300015487,
      "embedding_time_ms": 2289.250500034541,
      "retrieval_time_ms": 1224.300390004646,
      "decision_time_ms": 816.2002600030974,
      "memory_mb": -511.40234375,
      "token_count": 483,
      "timestamp": "2025-10-30T02:37:22.957536"
    },
    {
      "experiment_name": "v1.0 (Nomic, 768d)",
      "query": "What are the benefits of multi-scale embeddings?",
      "model": "nomic-ai/nomic-embed-text-v1.5",
      "scales": [
        768
      ],
      "confidence": 0.3568659836237878,
      "relevance_score": 0.85,
      "response_length": 1877,
      "latency_ms": 3977.840300067328,
      "embedding_time_ms": 2123.9359999308363,
      "retrieval_time_ms": 1193.3520900201984,
      "decision_time_ms": 795.5680600134656,
      "memory_mb": 4.69140625,
      "token_count": 476,
      "timestamp": "2025-10-30T02:37:27.067840"
    },
    {
      "experiment_name": "v1.0 (Nomic, 768d)",
      "query": "How do knowledge graphs improve retrieval?",
      "model": "nomic-ai/nomic-embed-text-v1.5",
      "scales": [
        768
      ],
      "confidence": 0.3036964303355674,
      "relevance_score": 0.85,
      "response_length": 1889,
      "latency_ms": 3967.2140000620857,
      "embedding_time_ms": 2156.6270999610424,
      "retrieval_time_ms": 1190.1642000186257,
      "decision_time_ms": 793.4428000124171,
      "memory_mb": 5.00390625,
      "token_count": 478,
      "timestamp": "2025-10-30T02:37:31.169875"
    },
    {
      "experiment_name": "v1.0 (Nomic, 768d)",
      "query": "What is the role of attention in transformers?",
      "model": "nomic-ai/nomic-embed-text-v1.5",
      "scales": [
        768
      ],
      "confidence": 0.35702422349321516,
      "relevance_score": 0.85,
      "response_length": 1893,
      "latency_ms": 3843.7787999864668,
      "embedding_time_ms": 2106.5580000868067,
      "retrieval_time_ms": 1153.13363999594,
      "decision_time_ms": 768.7557599972934,
      "memory_mb": 4.51953125,
      "token_count": 481,
      "timestamp": "2025-10-30T02:37:35.149739"
    },
    {
      "experiment_name": "v1.0 (Nomic, 768d)",
      "query": "Explain Bayesian exploration vs exploitation",
      "model": "nomic-ai/nomic-embed-text-v1.5",
      "scales": [
        768
      ],
      "confidence": 0.32840796051594306,
      "relevance_score": 0.85,
      "response_length": 1874,
      "latency_ms": 4019.4112000754103,
      "embedding_time_ms": 2199.3345000082627,
      "retrieval_time_ms": 1205.823360022623,
      "decision_time_ms": 803.8822400150821,
      "memory_mb": 4.50390625,
      "token_count": 473,
      "timestamp": "2025-10-30T02:37:39.294161"
    },
    {
      "experiment_name": "v1.0 (Nomic, 768d)",
      "query": "What is semantic similarity?",
      "model": "nomic-ai/nomic-embed-text-v1.5",
      "scales": [
        768
      ],
      "confidence": 0.2923260444720325,
      "relevance_score": 0.85,
      "response_length": 1862,
      "latency_ms": 3905.2052999613807,
      "embedding_time_ms": 2126.1263000778854,
      "retrieval_time_ms": 1171.5615899884142,
      "decision_time_ms": 781.0410599922761,
      "memory_mb": 4.50390625,
      "token_count": 469,
      "timestamp": "2025-10-30T02:37:43.332100"
    },
    {
      "experiment_name": "v1.0 (Nomic, 768d)",
      "query": "How does recursive learning improve AI systems?",
      "model": "nomic-ai/nomic-embed-text-v1.5",
      "scales": [
        768
      ],
      "confidence": 0.2809160024702227,
      "relevance_score": 0.85,
      "response_length": 1910,
      "latency_ms": 4162.565500009805,
      "embedding_time_ms": 2114.795600064099,
      "retrieval_time_ms": 1248.7696500029415,
      "decision_time_ms": 832.513100001961,
      "memory_mb": 4.50390625,
      "token_count": 484,
      "timestamp": "2025-10-30T02:37:47.616708"
    },
    {
      "experiment_name": "v1.0 (Nomic, 768d)",
      "query": "What are the key components of a neural network?",
      "model": "nomic-ai/nomic-embed-text-v1.5",
      "scales": [
        768
      ],
      "confidence": 0.29270391769034143,
      "relevance_score": 0.85,
      "response_length": 1932,
      "latency_ms": 4343.182499986142,
      "embedding_time_ms": 2322.817699983716,
      "retrieval_time_ms": 1302.9547499958426,
      "decision_time_ms": 868.6364999972284,
      "memory_mb": 4.50390625,
      "token_count": 492,
      "timestamp": "2025-10-30T02:37:52.087397"
    }
  ]
}