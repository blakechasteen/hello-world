#!/usr/bin/env python3
"""
üîÑ NARRATIVE LOOP ENGINE
========================
Continuous narrative processing with intelligent batching and learning.

Features:
1. Auto-Loop Mode - Continuously process narrative queue
2. Batch Processing - Intelligently group similar narratives
3. Learning Mode - Improve domain detection from feedback
4. Priority Queue - Process urgent narratives first
5. Throttling - Prevent overload with rate limiting
6. Checkpoint/Resume - Save state and resume processing

Use Cases:
- Live chat monitoring (Discord, Slack, Matrix)
- Document queue processing (bulk analysis)
- Continuous learning (improve over time)
- Real-time feed analysis (Twitter, RSS, news)
- Multi-user collaborative analysis
"""

import asyncio
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass, field
from enum import Enum
import time
from collections import deque, defaultdict
import heapq
import json
from pathlib import Path

from .cross_domain_adapter import CrossDomainAdapter, NarrativeDomain
from .streaming_depth import StreamingNarrativeAnalyzer, StreamEvent


class LoopMode(Enum):
    """Loop execution modes."""
    CONTINUOUS = "continuous"      # Never stop, process forever
    BATCH = "batch"                # Process queue then stop
    SCHEDULED = "scheduled"        # Process at intervals
    ON_DEMAND = "on_demand"        # Process when triggered


class Priority(Enum):
    """Narrative priority levels."""
    LOW = 0
    NORMAL = 1
    HIGH = 2
    URGENT = 3


@dataclass
class NarrativeTask:
    """A narrative to be processed."""
    id: str
    text: str
    domain: Optional[str] = None
    priority: Priority = Priority.NORMAL
    timestamp: float = field(default_factory=time.time)
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def __lt__(self, other):
        """Compare by priority then timestamp for heap queue."""
        if self.priority != other.priority:
            return self.priority.value > other.priority.value
        return self.timestamp < other.timestamp


@dataclass
class LoopStats:
    """Statistics for loop processing."""
    tasks_processed: int = 0
    tasks_failed: int = 0
    total_processing_time: float = 0.0
    average_processing_time: float = 0.0
    domains_seen: Dict[str, int] = field(default_factory=lambda: defaultdict(int))
    depth_distribution: Dict[str, int] = field(default_factory=lambda: defaultdict(int))
    start_time: float = field(default_factory=time.time)
    
    def update(self, result: Dict[str, Any], processing_time: float):
        """Update statistics with new result."""
        self.tasks_processed += 1
        self.total_processing_time += processing_time
        self.average_processing_time = self.total_processing_time / self.tasks_processed
        
        domain = result.get('domain', 'unknown')
        self.domains_seen[domain] += 1
        
        depth = result['base_analysis'].get('max_depth', 'unknown')
        self.depth_distribution[depth] += 1


class NarrativeLoopEngine:
    """
    Continuous narrative processing engine with intelligent batching.
    
    Processes narratives in a loop, learning and adapting over time.
    """
    
    def __init__(
        self,
        mode: LoopMode = LoopMode.CONTINUOUS,
        max_queue_size: int = 1000,
        rate_limit: float = 10.0,  # tasks per second
        checkpoint_interval: int = 100,  # tasks
        checkpoint_path: Optional[Path] = None
    ):
        """
        Initialize loop engine.
        
        Args:
            mode: Loop execution mode
            max_queue_size: Maximum queue size
            rate_limit: Maximum tasks per second
            checkpoint_interval: Save state every N tasks
            checkpoint_path: Path to save checkpoints
        """
        self.mode = mode
        self.max_queue_size = max_queue_size
        self.rate_limit = rate_limit
        self.checkpoint_interval = checkpoint_interval
        self.checkpoint_path = checkpoint_path or Path("loop_checkpoint.json")
        
        self.adapter = CrossDomainAdapter()
        self.queue: List[NarrativeTask] = []  # Priority heap queue
        self.stats = LoopStats()
        self.running = False
        
        # Callbacks
        self.on_result: Optional[Callable] = None
        self.on_error: Optional[Callable] = None
        self.on_checkpoint: Optional[Callable] = None
        
        # Rate limiting
        self.task_times = deque(maxlen=int(rate_limit * 10))
        
        # Learning mode
        self.domain_patterns: Dict[str, List[str]] = defaultdict(list)
    
    def add_task(
        self,
        task_id: str,
        text: str,
        domain: Optional[str] = None,
        priority: Priority = Priority.NORMAL,
        metadata: Optional[Dict] = None
    ):
        """Add a task to the processing queue."""
        if len(self.queue) >= self.max_queue_size:
            raise ValueError(f"Queue full (max {self.max_queue_size})")
        
        task = NarrativeTask(
            id=task_id,
            text=text,
            domain=domain,
            priority=priority,
            metadata=metadata or {}
        )
        
        heapq.heappush(self.queue, task)
        print(f"‚úÖ Added task {task_id} (priority={priority.name}, queue_size={len(self.queue)})")
    
    def add_batch(self, tasks: List[Dict[str, Any]]):
        """Add multiple tasks at once."""
        for task in tasks:
            self.add_task(
                task_id=task['id'],
                text=task['text'],
                domain=task.get('domain'),
                priority=Priority[task.get('priority', 'NORMAL')],
                metadata=task.get('metadata')
            )
    
    async def _rate_limit_check(self):
        """Check if we're within rate limits."""
        now = time.time()
        
        # Remove old timestamps
        while self.task_times and self.task_times[0] < now - 1.0:
            self.task_times.popleft()
        
        # Check rate
        if len(self.task_times) >= self.rate_limit:
            sleep_time = 1.0 - (now - self.task_times[0])
            if sleep_time > 0:
                await asyncio.sleep(sleep_time)
        
        self.task_times.append(now)
    
    async def _process_task(self, task: NarrativeTask) -> Dict[str, Any]:
        """Process a single task."""
        start_time = time.time()
        
        try:
            # Auto-detect domain if not specified
            result = await self.adapter.analyze_with_domain(
                task.text,
                domain_name=task.domain,
                auto_detect=task.domain is None
            )
            
            processing_time = time.time() - start_time
            self.stats.update(result, processing_time)
            
            # Learn from result
            if task.domain is None:
                detected_domain = result['domain']
                self.domain_patterns[detected_domain].append(task.text[:100])
            
            # Checkpoint if needed
            if self.stats.tasks_processed % self.checkpoint_interval == 0:
                self._save_checkpoint()
            
            return {
                'task_id': task.id,
                'status': 'success',
                'result': result,
                'processing_time': processing_time,
                'metadata': task.metadata
            }
            
        except Exception as e:
            self.stats.tasks_failed += 1
            return {
                'task_id': task.id,
                'status': 'error',
                'error': str(e),
                'metadata': task.metadata
            }
    
    async def run(self):
        """Run the loop engine."""
        self.running = True
        print(f"üîÑ Starting loop engine (mode={self.mode.name})")
        print(f"   Rate limit: {self.rate_limit} tasks/sec")
        print(f"   Queue size: {len(self.queue)}")
        print()
        
        try:
            while self.running:
                # Check if queue is empty
                if not self.queue:
                    if self.mode == LoopMode.BATCH:
                        print("üì≠ Queue empty, batch complete!")
                        break
                    elif self.mode == LoopMode.CONTINUOUS:
                        # Wait for new tasks
                        await asyncio.sleep(1.0)
                        continue
                    elif self.mode == LoopMode.ON_DEMAND:
                        print("‚è∏Ô∏è  Waiting for tasks...")
                        await asyncio.sleep(1.0)
                        continue
                
                # Get next task (highest priority)
                await self._rate_limit_check()
                task = heapq.heappop(self.queue)
                
                print(f"üîÑ Processing task {task.id} (priority={task.priority.name}, queue={len(self.queue)})")
                
                # Process task
                result = await self._process_task(task)
                
                # Call result callback
                if self.on_result:
                    if asyncio.iscoroutinefunction(self.on_result):
                        await self.on_result(result)
                    else:
                        self.on_result(result)
                
                # Handle errors
                if result['status'] == 'error' and self.on_error:
                    if asyncio.iscoroutinefunction(self.on_error):
                        await self.on_error(result)
                    else:
                        self.on_error(result)
                
                # Print progress
                if self.stats.tasks_processed % 10 == 0:
                    self._print_progress()
        
        finally:
            self.running = False
            print()
            print("üèÅ Loop engine stopped")
            self._print_final_stats()
    
    def stop(self):
        """Stop the loop engine."""
        self.running = False
        print("üõë Stopping loop engine...")
    
    def _print_progress(self):
        """Print current progress."""
        uptime = time.time() - self.stats.start_time
        rate = self.stats.tasks_processed / uptime if uptime > 0 else 0
        
        print(f"üìä Progress: {self.stats.tasks_processed} tasks processed, "
              f"{len(self.queue)} queued, "
              f"{rate:.1f} tasks/sec, "
              f"avg {self.stats.average_processing_time*1000:.1f}ms")
    
    def _print_final_stats(self):
        """Print final statistics."""
        print("=" * 80)
        print("üìà FINAL STATISTICS")
        print("=" * 80)
        print(f"Tasks processed: {self.stats.tasks_processed}")
        print(f"Tasks failed: {self.stats.tasks_failed}")
        print(f"Success rate: {(1 - self.stats.tasks_failed/max(self.stats.tasks_processed, 1))*100:.1f}%")
        print(f"Total time: {self.stats.total_processing_time:.1f}s")
        print(f"Average time: {self.stats.average_processing_time*1000:.1f}ms per task")
        print()
        
        print("Domain Distribution:")
        for domain, count in sorted(self.stats.domains_seen.items(), key=lambda x: x[1], reverse=True):
            print(f"  {domain:15} : {count:4} tasks ({count/self.stats.tasks_processed*100:.1f}%)")
        print()
        
        print("Depth Distribution:")
        for depth, count in sorted(self.stats.depth_distribution.items(), key=lambda x: x[1], reverse=True):
            print(f"  {depth:15} : {count:4} tasks ({count/self.stats.tasks_processed*100:.1f}%)")
        print("=" * 80)
    
    def _save_checkpoint(self):
        """Save current state to checkpoint."""
        checkpoint = {
            'stats': {
                'tasks_processed': self.stats.tasks_processed,
                'tasks_failed': self.stats.tasks_failed,
                'domains_seen': dict(self.stats.domains_seen),
                'depth_distribution': dict(self.stats.depth_distribution)
            },
            'queue_size': len(self.queue),
            'timestamp': time.time()
        }
        
        self.checkpoint_path.write_text(json.dumps(checkpoint, indent=2))
        print(f"üíæ Checkpoint saved ({self.stats.tasks_processed} tasks)")
        
        if self.on_checkpoint:
            self.on_checkpoint(checkpoint)


async def demonstrate_loop_modes():
    """Demonstrate different loop modes."""
    print("üîÑ NARRATIVE LOOP ENGINE DEMONSTRATION")
    print("=" * 80)
    print()
    
    # Sample narratives from different domains
    sample_narratives = [
        {
            'id': 'business_1',
            'text': 'The startup pivoted after realizing customers wanted clarity, not features.',
            'domain': 'business',
            'priority': 'NORMAL'
        },
        {
            'id': 'science_1',
            'text': 'The experiment failed three times before revealing the paradigm shift.',
            'domain': 'science',
            'priority': 'HIGH'
        },
        {
            'id': 'personal_1',
            'text': 'In therapy, facing my shadow became the doorway to healing.',
            'domain': 'personal',
            'priority': 'NORMAL'
        },
        {
            'id': 'urgent_1',
            'text': 'BREAKING: The protesters gathered as the regime crumbled.',
            'domain': 'history',
            'priority': 'URGENT'
        },
        {
            'id': 'product_1',
            'text': 'User interviews revealed we solved the wrong problem entirely.',
            'domain': 'product',
            'priority': 'NORMAL'
        },
        {
            'id': 'mythology_1',
            'text': 'Odysseus faced the cyclops and learned that pride is the greatest enemy.',
            'domain': 'mythology',
            'priority': 'LOW'
        }
    ]
    
    # Demo 1: Batch Mode
    print("üì¶ DEMO 1: BATCH MODE")
    print("   Process queue then stop")
    print("-" * 80)
    
    engine = NarrativeLoopEngine(
        mode=LoopMode.BATCH,
        rate_limit=2.0  # 2 tasks/sec for demo
    )
    
    # Add results callback
    results = []
    def on_result(result):
        results.append(result)
        if result['status'] == 'success':
            domain = result['result']['domain']
            depth = result['result']['base_analysis']['max_depth']
            print(f"   ‚úÖ {result['task_id']}: {domain} ‚Üí {depth}")
    
    engine.on_result = on_result
    
    # Add tasks
    engine.add_batch(sample_narratives)
    
    # Run batch
    await engine.run()
    
    print()
    print(f"‚úÖ Batch complete! Processed {len(results)} narratives")
    print()
    
    # Demo 2: Priority Queue
    print("‚ö° DEMO 2: PRIORITY QUEUE")
    print("   Urgent tasks processed first")
    print("-" * 80)
    
    engine2 = NarrativeLoopEngine(
        mode=LoopMode.BATCH,
        rate_limit=3.0
    )
    
    processing_order = []
    def track_order(result):
        processing_order.append((result['task_id'], result['metadata'].get('priority')))
        print(f"   üìù Processed: {result['task_id']} (priority={result['metadata'].get('priority')})")
    
    engine2.on_result = track_order
    
    # Add tasks in random order but with different priorities
    engine2.add_batch(sample_narratives)
    
    await engine2.run()
    
    print()
    print("Processing order:")
    for task_id, priority in processing_order:
        print(f"   {task_id:15} (priority={priority})")
    print()
    
    # Demo 3: Learning Mode
    print("üß† DEMO 3: LEARNING MODE")
    print("   Auto-detect domains and learn patterns")
    print("-" * 80)
    
    engine3 = NarrativeLoopEngine(
        mode=LoopMode.BATCH,
        rate_limit=3.0
    )
    
    # Remove domain hints to test auto-detection
    auto_detect_tasks = [
        {**task, 'domain': None}
        for task in sample_narratives
    ]
    
    def show_learning(result):
        if result['status'] == 'success':
            detected = result['result']['domain']
            print(f"   üîç {result['task_id']}: Auto-detected as '{detected}'")
    
    engine3.on_result = show_learning
    engine3.add_batch(auto_detect_tasks)
    
    await engine3.run()
    
    print()
    print("Learned domain patterns:")
    for domain, patterns in engine3.domain_patterns.items():
        print(f"   {domain:15} : {len(patterns)} examples")
    print()
    
    print("=" * 80)
    print("üéâ LOOP ENGINE DEMO COMPLETE!")
    print()
    print("‚ú® Features Demonstrated:")
    print("   ‚úÖ Batch processing (process queue then stop)")
    print("   ‚úÖ Priority queue (urgent tasks first)")
    print("   ‚úÖ Auto-detection learning (improve over time)")
    print("   ‚úÖ Rate limiting (prevent overload)")
    print("   ‚úÖ Statistics tracking (performance metrics)")
    print("   ‚úÖ Callback hooks (extensible)")
    print()
    print("üöÄ Ready for continuous narrative processing!")
    print("=" * 80)


if __name__ == "__main__":
    asyncio.run(demonstrate_loop_modes())
